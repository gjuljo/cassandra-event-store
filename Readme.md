# CASSADRA EVENT STORE

## OVERVIEW

This project is a inspired by [Mathew McLoughlin's talk at NDC London 2017](https://www.youtube.com/watch?v=9a1PqwFrMP0) and the more recent [article by Victor MartÃ­nez](https://victoramartinez.com/posts/event-sourcing-in-go/) about CQRS and Event Sourcing implementation in Go.
The objective is to have a simple and well known example to experiment with a basic **Event Store** implemented using [Apache Cassandra](https://cassandra.apache.org/) and to evaluate pros and cons of such an implementation.

--------------------------------------------------------------------------------------------------------------------------------

## KEYSPACES AND REPLICAS

According to the topology of the Cassandra cluster, you might need to create the `eventstore` keyspace as follows:

- single node in single datacenter

```
CREATE KEYSPACE IF NOT EXISTS eventstore WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 1};
```

- multiple nodes in single datacenter

```
CREATE KEYSPACE IF NOT EXISTS eventstore WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 3};
```

- multiple nodes in multiple datacenters

```
CREATE KEYSPACE IF NOT EXISTS eventstore WITH REPLICATION = {'class':'NetworkTopologyStrategy','DC1':3,'DC2':3,'DC3':3};
```

--------------------------------------------------------------------------------------------------------------------------------

## TABLES AND MATERIALIZED VIEWS

The solution uses just one **table** and one **materialized view** to allow queries by domain aggregate id and by event type respectively. The materialized view allows to gather the events by event type to implement the [Transactional Outbox Pattern](https://microservices.io/patterns/data/transactional-outbox.html) and let processes to poll for new instances of a given type of event by reading only one partition.

As you can see later, we use **batch statements** with **conditional clauses** to insert events in the table to get the outcome of the batch transitions and implement a [Optimistic Concurrency Control (OCC)](https://en.wikipedia.org/wiki/Optimistic_concurrency_control) mechanism. This ensures that events are inserted only if the domain aggregate has not changed in the meanwhile.

These statements involve **lightweight transitions**, also known as known as **compare and set (CAS)**, as data is compared and any data found to be out of date is set to the most consistent value. It's a [linearizable consistency](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlLtwtTransactions.html) mechanism made with [Paxos](https://www.usenix.org/system/files/hotstorage19-paper-charapko.pdf).

### EVENT TABLE

The following is a possible implementation of a Cassandra table to store events independently of the actual type of the event and its payload.
By adopting the UUID of the domain aggregate as **partition key** of the table, all the events are stored in the same partition and this speeds up queries and updates. Domain aggregate `version` also needed in the **primary key** of the table to let multiple events coexist in the same partition and also the `savetime` is needed to order them in the materialized view that, instead, gathers all the events of the same `type` in the same partition.

To handle the **optimistic locking** mechanism, we need a **static** column that allows us to use conditional statements in the batch statements and discard any table change in case the aggregate has evolved since the expected version that the events we wanted to persist were meant for.

```
CREATE TABLE IF NOT EXISTS eventstore.events (
  id               UUID,                -- uuid of the domain aggregate that the event is related to
  version          int,                 -- version of the domain aggregate generated by that event
  type             int,                 -- type of event
  payload          text,                -- actual payload of the event, typically in a JSON format 
  savetime         timestamp,           -- save time of the event, actually needed to order events in the materialized view
  current_version  int STATIC,          -- current version of the domain aggregate, corresponding to the biggest version
  PRIMARY KEY (id, version, savetime)
);
```

### EVENT-BY-TYPE MATERIALIZED VIEW

This materialized view is meant to gather all the events of the same type in the same partition, to let queries such as "events by type". It enables processes that need to react whether a given type of event occurred.

```
CREATE MATERIALIZED VIEW IF NOT EXISTS eventstore.events_by_type AS
  SELECT id, version, type, payload, savetime FROM eventstore.events WHERE type IS NOT NULL AND version IS NOT NULL AND savetime IS NOT NULL
PRIMARY KEY (type, savetime, version, id);
```

--------------------------------------------------------------------------------------------------------------------------------

## CQL BATCH STATEMENTS

To implement the **optimistic locking strategy** we have to insert new events in the table only if the domain aggregate has not changed version since our previous read. In Cassandra this is possible by writing all the events in a **batch statement**, using the `current_version` of the aggregate as condition.

The following CQL statements are meant for the scenario when, programmatically, we use the **lightweight transaction** feature of Cassandra, so we have an immediate feedback from the API about the actual application of the batch statement.

When we add an event to the table we distinguish between two different cases:

- when the domain aggregate is new and it's not expected to be in the table

- when the domain aggregate is already existing and expected to be at a given `current_version`

### FIRST EVENT

Here follows an example for a batch statement meant to insert one event for a new domain aggregate in the table:

```
BEGIN BATCH
INSERT INTO eventstore.events (id, current_version) VALUES (fade87a1-9df9-46bb-aae6-63b2b763094d, 1) IF NOT EXISTS;
INSERT INTO eventstore.events (id, version, type, payload, savetime) VALUES (fade87a1-9df9-46bb-aae6-63b2b763094d, 1, 11, 'aaa', toTimeStamp(now()));
APPLY BATCH;
```

If the batch is successfully applied, the table is supposed to contain the following row:

#### *events* table

| id (P) | version (C) | savetime (C) | current_version (S) | payload | type |
|--------|------------:|--------------|--------------------:|--------:|-----:|
|fade87a1-9df9-46bb-aae6-63b2b763094d | 1 | 2020-11-24 18:21:49.826000+0000 | 1 | 'aaa' | 11 |

Correspondingly, the materialized view is supposed to have the following contents:

#### *events_by_type* view

| type (P) | savetype (C) | version (C) | id | payload |
|----------|--------------|------------:|----|--------:|
|11| 2020-11-24 18:21:49.826000+0000 | 1 | fade87a1-9df9-46bb-aae6-63b2b763094d|'aaa'|

### FURTHER EVENTS

The next batch statement shows how to insert subsequent events when the domain aggregate is supposed to already exist with an expected `current_version` (in this case `1`):

```
BEGIN BATCH
UPDATE eventstore.events SET current_version = 3 WHERE id = fade87a1-9df9-46bb-aae6-63b2b763094d IF current_version = 1;
INSERT INTO eventstore.events (id, version, type, payload, savetime) VALUES (fade87a1-9df9-46bb-aae6-63b2b763094d, 2, 22, 'bbb', toTimeStamp(now()));
INSERT INTO eventstore.events (id, version, type, payload, savetime) VALUES (fade87a1-9df9-46bb-aae6-63b2b763094d, 3, 33, 'ccc', toTimeStamp(now()));
APPLY BATCH;
```

If the batch is successfully applied, the table is supposed to contain the following rows:

#### *events* table

| id (P) | version (C) | savetime (C) | current_version (S) | payload | type |
|--------|------------:|--------------|--------------------:|--------:|-----:|
|fade87a1-9df9-46bb-aae6-63b2b763094d | 1 | 2020-11-24 18:21:49.826000+0000 | 3 | 'aaa' | 11 |
|fade87a1-9df9-46bb-aae6-63b2b763094d | 2 | 2020-11-24 18:21:49.827000+0000 | 3 | 'bbb' | 22 |
|fade87a1-9df9-46bb-aae6-63b2b763094d | 3 | 2020-11-24 18:21:49.828000+0000 | 3 | 'ccc' | 33 |

Please notice the `current_version` column that, being static, has the same value for all the rows and it is equal to the latest version of the domain aggregate.

The corresponding materialized view should be the following:

#### *events_by_type* view

| type (P) | savetype (C) | version (C) | id | payload |
|----------|--------------|------------:|----|--------:|
|11| 2020-11-24 18:21:49.826000+0000 | 1 | fade87a1-9df9-46bb-aae6-63b2b763094d|'aaa'|
|22| 2020-11-24 18:21:49.827000+0000 | 2 | fade87a1-9df9-46bb-aae6-63b2b763094d|'bbb'|
|33| 2020-11-24 18:21:49.828000+0000 | 3 | fade87a1-9df9-46bb-aae6-63b2b763094d|'ccc'|

--------------------------------------------------------------------------------------------------------------------------------

## QUERIES AT HAND

```
SELECT * FROM eventstore.events LIMIT 100;
SELECT * FROM eventstore.events_by_type LIMIT 100;

SELECT COUNT(*) FROM eventstore.events_by_type WHERE type = 2;
SELECT * FROM eventstore.events_by_type WHERE type = 1 AND savetime >= 1606154195500;
SELECT * FROM eventstore.events_by_type WHERE type = 1 AND savetime >= '2020-11-23';

TRUNCATE TABLE eventstore.events;
DROP TABLE eventstore.events;
DROP MATERIALIZED VIEW eventstore.events_by_type;
```

--------------------------------------------------------------------------------------------------------------------------------

## RUNNING LOCALLY (Windows example)
In this scenario you run Cassandra in Docker, while both **gRPC** client and server run on you local workstation. You are supposed to have already installed [Go](https://golang.org/) and [Protocol Buffer Compiler](https://grpc.io/docs/protoc-installation/).

1. START CASSANDRA

    ```
    docker-compose up -d cassandra
    ```

    optionally you can start a **cqlsh** session to query the database as needed:

    ```bash
    docker-compose exec cassandra cqlsh
    ```

2. CRATE KEYSPACE AND TABLES

    ```
    docker-compose up gentables
    ```

3. GERENRATE PROTOBUFFER

    ```
    protoc --go_out=esexample --go-grpc_out=esexample esexample\store\grpc-store.proto
    ```

4. BUILD AND START THE SERVER

    ```
    cd esexample\cmd\grpc-store
    go build && grpc-store.exe
    ```

5. BUILD AND START THE POLLING CLIENT

    ```
    cd esexample\cmd\polling-client
    go build && polling-client.exe
    ```

6. BUILD AND START THE CLIENT

    ```
    cd esexample\cmd\test-client
    go build && test-client.exe
    ```

--------------------------------------------------------------------------------------------------------------------------------

## TRAFFIC MIRRORING WITH ENVOY

In this example we see how to mirror the gRPC traffic from client to the server using **Envoy** in between. Anything sent to the server is also sent to a *sink* server that only logs the traffic.

1. START CASSANDRA

    ```
    docker-compose up -d cassandra
    ```

    optionally you can start a **cqlsh** session to query the database as needed:

    ```bash
    docker-compose exec cassandra cqlsh
    ```

2. CRATE KEYSPACE AND TABLES

    ```
    docker-compose up gentables
    ```

3. START POLLING CLIENT, ENVOY, STORE AND SINK SERVICES

    ```
    docker-compose up grpc-store grpc-sink envoy poll-client
    ```

4. BUILD AND START THE CLIENT

    ```
    cd esexample\cmd\test-client
    go build && test-client.exe
    ```

--------------------------------------------------------------------------------------------------------------------------------

## MANUALLY GENERATE THE DOCKER IMAGES

The **docker-compose** file generates all the Docker images, but you can manually build them if needed:

* gRPC STORE SERVER

    ```bash
    docker build -t esexample/grpc-store -f Dockerfile.grpcstore .
    ```

* gRPC SINK SERVER

    ```bash
    docker build -t esexample/grpc-sink -f Dockerfile.grpcsink .
    ```

* gRPC POLLING CLIENT

    ```bash
    docker build -t esexample/poll-client -f Dockerfile.pollclient .
    ```

--------------------------------------------------------------------------------------------------------------------------------

## REFERENCES

- [An Introduction to CQRS and Event Sourcing Patterns - Mathew McLoughlin]([https://www.youtube.com/watch?v=9a1PqwFrMP0])
- [PatientMangement project on GitHub - Mathew McLoughlin](https://github.com/mat-mcloughlin/PatientMangement)
- [Event Sourcing in Go - Victor MartÃ­nez](https://victoramartinez.com/posts/event-sourcing-in-go/)
- [Building Microservices with Event Sourcing/CQRS in Go using gRPC, NATS Streaming and CockroachDB - Shiju Varghese](https://shijuvar.medium.com/building-microservices-with-event-sourcing-cqrs-in-go-using-grpc-nats-streaming-and-cockroachdb-983f650452aa)
- [Simple CQRS Implementation in C# - Gergory Young](https://github.com/gregoryyoung/m-r/tree/master/SimpleCQRS)
- [Shadow Traffic with Envoy](https://pankaj-takawale.medium.com/shadow-traffic-with-envoy-952c924f1eba)
- [gRPC Quick Start](https://grpc.io/docs/platforms/web/quickstart/)